{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marvinko99/rna-folding-tranformermodel?scriptVersionId=236496110\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e44eb2ef","metadata":{"papermill":{"duration":0.004002,"end_time":"2025-04-27T22:29:03.595787","exception":false,"start_time":"2025-04-27T22:29:03.591785","status":"completed"},"tags":[]},"source":["# Transformer Model for Stanford RNA 3D Folding Kaggle Competition\n","This notebook implements a deep learning model for predicting the 3D structure of RNA molecules based on their sequences. The competition aims to advance RNA-based medicine and biotechnology by improving our understanding of RNA folding. The model, a simplified version of RhoFold+, is a transformer-based architecture designed to predict RNA 3D structures. It includes data preprocessing, a custom dataset class, a transformer encoder, and a training loop. The predictions are evaluated using the TM-score metric, which measures the alignment of predicted and experimental structures. The final submission file contains the x, y, z coordinates of the C1' atom for each residue across five predicted structures."]},{"cell_type":"code","execution_count":1,"id":"20bd11cd","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-27T22:29:03.603563Z","iopub.status.busy":"2025-04-27T22:29:03.603231Z","iopub.status.idle":"2025-04-27T22:29:07.501304Z","shell.execute_reply":"2025-04-27T22:29:07.50064Z"},"papermill":{"duration":3.903595,"end_time":"2025-04-27T22:29:07.502862","exception":false,"start_time":"2025-04-27T22:29:03.599267","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define constants\n","MAX_SEQ_LENGTH = 512  # Maximum sequence length\n","EMBEDDING_DIM = 256   # Dimension of embeddings\n","NUM_HEADS = 4         # Number of attention heads\n","NUM_LAYERS = 4        # Number of transformer layers\n","HIDDEN_DIM = 512      # Hidden dimension for feed-forward layers\n","BATCH_SIZE = 4       # Batch size\n","LEARNING_RATE = 3e-4  # Learning rate\n","NUM_EPOCHS = 20       # Number of training epochs\n","NUM_PREDICTIONS = 5   # Number of structure predictions required\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"markdown","id":"7ea20ed7","metadata":{"papermill":{"duration":0.003089,"end_time":"2025-04-27T22:29:07.509647","exception":false,"start_time":"2025-04-27T22:29:07.506558","status":"completed"},"tags":[]},"source":["# Load and Preprocess Data\n","In this section, the RNA sequence data and labels are loaded from CSV files. The maximum sequence length is calculated to ensure consistent input dimensions for the model."]},{"cell_type":"code","execution_count":2,"id":"418dc11b","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:07.517098Z","iopub.status.busy":"2025-04-27T22:29:07.516719Z","iopub.status.idle":"2025-04-27T22:29:07.939834Z","shell.execute_reply":"2025-04-27T22:29:07.938736Z"},"papermill":{"duration":0.428356,"end_time":"2025-04-27T22:29:07.941207","exception":false,"start_time":"2025-04-27T22:29:07.512851","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Maximum sequence length in dataset: 4298\n"]}],"source":["    # Load data\n","train_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n","train_labels = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n","validation_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv')\n","validation_labels = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/validation_labels.csv')\n","test_sequences = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n","sample_submission = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/sample_submission.csv')\n","\n","\n","#set Max_SEQ_length\n","max_len = max(train_sequences['sequence'].str.len().max(), \n","              validation_sequences['sequence'].str.len().max(),\n","              test_sequences['sequence'].str.len().max())\n","print(f\"Maximum sequence length in dataset: {max_len}\")\n","MAX_SEQ_LENGTH = max_len"]},{"cell_type":"markdown","id":"c8968d5b","metadata":{"papermill":{"duration":0.003202,"end_time":"2025-04-27T22:29:07.948066","exception":false,"start_time":"2025-04-27T22:29:07.944864","status":"completed"},"tags":[]},"source":["# Define RNA Dataset Class\n","The `RNADataset` class is implemented to handle RNA sequence data. It encodes sequences, creates attention masks, and prepares labels for training and validation."]},{"cell_type":"code","execution_count":3,"id":"7f678f9d","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:07.955402Z","iopub.status.busy":"2025-04-27T22:29:07.955179Z","iopub.status.idle":"2025-04-27T22:29:07.963486Z","shell.execute_reply":"2025-04-27T22:29:07.962907Z"},"papermill":{"duration":0.013381,"end_time":"2025-04-27T22:29:07.964717","exception":false,"start_time":"2025-04-27T22:29:07.951336","status":"completed"},"tags":[]},"outputs":[],"source":["# RNA Dataset class\n","class RNADataset(Dataset):\n","    def __init__(self, sequences, labels=None, is_test=False):\n","        self.sequences = sequences\n","        self.labels = labels\n","        self.is_test = is_test\n","        self.nucleotide_map = {'A': 1, 'C': 2, 'G': 3, 'U': 4, 'T': 4}\n","        \n","        if not is_test and labels is not None:\n","            # Extract target_id from ID in labels\n","            self.labels['target_id'] = self.labels['ID'].apply(\n","                lambda x: '_'.join(x.split('_')[:-1]) if '_' in x else x\n","            )\n","    \n","    def __len__(self):\n","        return len(self.sequences)\n","    \n","    def __getitem__(self, idx):\n","        sequence_row = self.sequences.iloc[idx]\n","        target_id = sequence_row['target_id']\n","        sequence = sequence_row['sequence']\n","        \n","        # Encode sequence\n","        encoded_seq = np.zeros(MAX_SEQ_LENGTH, dtype=np.int64)\n","        for i, nuc in enumerate(sequence[:MAX_SEQ_LENGTH]):\n","            encoded_seq[i] = self.nucleotide_map.get(nuc, 0)\n","        \n","        # Create attention mask\n","        seq_length = min(len(sequence), MAX_SEQ_LENGTH)\n","        attention_mask = np.zeros(MAX_SEQ_LENGTH, dtype=np.int64)\n","        attention_mask[:seq_length] = 1\n","        \n","        result = {\n","            'target_id': target_id,\n","            'sequence': sequence,\n","            'encoded_seq': torch.tensor(encoded_seq),\n","            'attention_mask': torch.tensor(attention_mask),\n","            'seq_length': seq_length\n","        }\n","        \n","        if not self.is_test and self.labels is not None:\n","            # Find all labels for this target_id\n","            target_labels = self.labels[self.labels['target_id'] == target_id]\n","            \n","            if len(target_labels) > 0:\n","                # Extract coordinates\n","                coords = np.zeros((MAX_SEQ_LENGTH, 3), dtype=np.float32)\n","                mask = np.zeros(MAX_SEQ_LENGTH, dtype=np.float32)\n","                \n","                for i in range(1, seq_length + 1):\n","                    # Find row with matching resid\n","                    label_row = target_labels[target_labels['resid'] == i]\n","                    \n","                    if len(label_row) > 0:\n","                        x = label_row['x_1'].values[0]\n","                        y = label_row['y_1'].values[0]\n","                        z = label_row['z_1'].values[0]\n","                        \n","                        if not (pd.isna(x) or pd.isna(y) or pd.isna(z)):\n","                            coords[i-1] = [x, y, z]\n","                            mask[i-1] = 1.0\n","                \n","                result['coords'] = torch.tensor(coords)\n","                result['mask'] = torch.tensor(mask)\n","        \n","        return result\n"]},{"cell_type":"markdown","id":"ddfa5168","metadata":{"papermill":{"duration":0.003051,"end_time":"2025-04-27T22:29:07.971101","exception":false,"start_time":"2025-04-27T22:29:07.96805","status":"completed"},"tags":[]},"source":["# Transformer Encoder Layer\n","This section defines the Transformer encoder layer, which includes self-attention and feed-forward layers with residual connections and layer normalization."]},{"cell_type":"code","execution_count":4,"id":"e94a5fe2","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:07.978296Z","iopub.status.busy":"2025-04-27T22:29:07.978093Z","iopub.status.idle":"2025-04-27T22:29:07.983099Z","shell.execute_reply":"2025-04-27T22:29:07.982531Z"},"papermill":{"duration":0.009886,"end_time":"2025-04-27T22:29:07.984219","exception":false,"start_time":"2025-04-27T22:29:07.974333","status":"completed"},"tags":[]},"outputs":[],"source":["# Transformer encoder layer\n","class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, nhead, dim_feedforward=HIDDEN_DIM, dropout=0.1):\n","        super(TransformerEncoderLayer, self).__init__()\n","        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n","        self.linear1 = nn.Linear(d_model, dim_feedforward)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear2 = nn.Linear(dim_feedforward, d_model)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.activation = nn.ReLU()\n","    \n","    def forward(self, src, src_mask=None):\n","        # Self attention with residual connection and layer norm\n","        src2, _ = self.self_attn(src, src, src, key_padding_mask=src_mask)\n","        src = src + self.dropout(src2)\n","        src = self.norm1(src)\n","        \n","        # Feed forward with residual connection and layer norm\n","        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n","        src = src + self.dropout(src2)\n","        src = self.norm2(src)\n","        \n","        return src\n"]},{"cell_type":"markdown","id":"6dec07bf","metadata":{"papermill":{"duration":0.003088,"end_time":"2025-04-27T22:29:07.99068","exception":false,"start_time":"2025-04-27T22:29:07.987592","status":"completed"},"tags":[]},"source":["# RhoFold+ Model\n","The RhoFold+ model is a simplified transformer-based architecture designed for RNA 3D structure prediction. It includes embedding layers, positional encodings, and multiple transformer layers."]},{"cell_type":"code","execution_count":5,"id":"212226be","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:07.997922Z","iopub.status.busy":"2025-04-27T22:29:07.997717Z","iopub.status.idle":"2025-04-27T22:29:08.003482Z","shell.execute_reply":"2025-04-27T22:29:08.002824Z"},"papermill":{"duration":0.010848,"end_time":"2025-04-27T22:29:08.004793","exception":false,"start_time":"2025-04-27T22:29:07.993945","status":"completed"},"tags":[]},"outputs":[],"source":["# RhoFold+ model (simplified)\n","class RhoFoldPlus(nn.Module):\n","    def __init__(self, vocab_size=5):\n","        super(RhoFoldPlus, self).__init__()\n","        \n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=0)\n","        \n","        # Positional encoding\n","        self.pos_encoder = nn.Embedding(MAX_SEQ_LENGTH, EMBEDDING_DIM)\n","        \n","        # Transformer encoder layers\n","        self.transformer_layers = nn.ModuleList([\n","            TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS)\n","            for _ in range(NUM_LAYERS)\n","        ])\n","        \n","        # Output heads for coordinate prediction (multiple heads for diverse predictions)\n","        self.coordinate_heads = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(EMBEDDING_DIM, HIDDEN_DIM),\n","                nn.ReLU(),\n","                nn.Dropout(0.1),\n","                nn.Linear(HIDDEN_DIM, HIDDEN_DIM // 2),\n","                nn.ReLU(),\n","                nn.Linear(HIDDEN_DIM // 2, 3)  # x, y, z coordinates\n","            )\n","            for _ in range(NUM_PREDICTIONS)\n","        ])\n","    \n","    def forward(self, input_ids, attention_mask):\n","        # Create padding mask for attention (True for padding positions)\n","        padding_mask = (attention_mask == 0)\n","        \n","        # Create position indices\n","        batch_size, seq_len = input_ids.size()\n","        positions = torch.arange(0, seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, -1)\n","        \n","        # Embedding lookup\n","        x = self.embedding(input_ids)\n","        pos_emb = self.pos_encoder(positions)\n","        \n","        # Add positional embeddings\n","        x = x + pos_emb\n","        \n","        # Apply transformer layers\n","        for layer in self.transformer_layers:\n","            x = layer(x, padding_mask)\n","        \n","        # Predict coordinates using different heads for diverse predictions\n","        coordinates = [head(x) for head in self.coordinate_heads]\n","        \n","        return coordinates\n"]},{"cell_type":"markdown","id":"3e3cd40e","metadata":{"papermill":{"duration":0.003129,"end_time":"2025-04-27T22:29:08.011431","exception":false,"start_time":"2025-04-27T22:29:08.008302","status":"completed"},"tags":[]},"source":["# Loss Function\n","The `MaskedMSELoss` class implements a custom loss function that calculates the mean squared error for valid positions in the RNA sequence."]},{"cell_type":"code","execution_count":6,"id":"193561c8","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:08.019029Z","iopub.status.busy":"2025-04-27T22:29:08.018823Z","iopub.status.idle":"2025-04-27T22:29:08.022583Z","shell.execute_reply":"2025-04-27T22:29:08.02201Z"},"papermill":{"duration":0.008829,"end_time":"2025-04-27T22:29:08.023885","exception":false,"start_time":"2025-04-27T22:29:08.015056","status":"completed"},"tags":[]},"outputs":[],"source":["# Loss function with masking for valid positions\n","class MaskedMSELoss(nn.Module):\n","    def __init__(self):\n","        super(MaskedMSELoss, self).__init__()\n","    \n","    def forward(self, pred, target, mask):\n","        # Expand mask to match dimensions\n","        mask = mask.unsqueeze(-1).expand_as(pred)\n","        \n","        # Calculate squared error\n","        squared_error = (pred - target) ** 2\n","        \n","        # Apply mask and calculate mean\n","        masked_error = squared_error * mask\n","        loss = masked_error.sum() / (mask.sum() + 1e-8)\n","        \n","        return loss\n"]},{"cell_type":"markdown","id":"330f0d74","metadata":{"papermill":{"duration":0.003277,"end_time":"2025-04-27T22:29:08.030586","exception":false,"start_time":"2025-04-27T22:29:08.027309","status":"completed"},"tags":[]},"source":["# Training the Model\n","This section defines the training loop for the RhoFold+ model. It includes forward and backward passes, loss calculation, and model evaluation on the validation set."]},{"cell_type":"code","execution_count":7,"id":"4148462a","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:08.038333Z","iopub.status.busy":"2025-04-27T22:29:08.038127Z","iopub.status.idle":"2025-04-27T22:29:08.045026Z","shell.execute_reply":"2025-04-27T22:29:08.044411Z"},"papermill":{"duration":0.012053,"end_time":"2025-04-27T22:29:08.046166","exception":false,"start_time":"2025-04-27T22:29:08.034113","status":"completed"},"tags":[]},"outputs":[],"source":["# Training function\n","def train_model(model, train_loader, val_loader):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    criterion = MaskedMSELoss()\n","    \n","    best_val_loss = float('inf')\n","    best_model_state = None\n","    \n","    for epoch in range(NUM_EPOCHS):\n","        # Training\n","        model.train()\n","        train_loss = 0.0\n","        \n","        for batch in train_loader:\n","            input_ids = batch['encoded_seq'].to(DEVICE)\n","            attention_mask = batch['attention_mask'].to(DEVICE)\n","            target_coords = batch['coords'].to(DEVICE)\n","            mask = batch['mask'].to(DEVICE)\n","            \n","            # Forward pass\n","            pred_coords_list = model(input_ids, attention_mask)\n","            \n","            # Calculate loss for all prediction heads\n","            loss = 0.0\n","            for pred_coords in pred_coords_list:\n","                loss += criterion(pred_coords, target_coords, mask)\n","            loss /= len(pred_coords_list)\n","            \n","            # Backward pass\n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            \n","            train_loss += loss.item()\n","        \n","        train_loss /= len(train_loader)\n","        \n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        \n","        with torch.no_grad():\n","            for batch in val_loader:\n","                input_ids = batch['encoded_seq'].to(DEVICE)\n","                attention_mask = batch['attention_mask'].to(DEVICE)\n","                target_coords = batch['coords'].to(DEVICE)\n","                mask = batch['mask'].to(DEVICE)\n","                \n","                # Forward pass\n","                pred_coords_list = model(input_ids, attention_mask)\n","                \n","                # Calculate loss\n","                batch_loss = 0.0\n","                for pred_coords in pred_coords_list:\n","                    batch_loss += criterion(pred_coords, target_coords, mask)\n","                batch_loss /= len(pred_coords_list)\n","                \n","                val_loss += batch_loss.item()\n","        \n","        val_loss /= len(val_loader)\n","        \n","        print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n","        \n","        # Save best model\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","            print(f'New best model saved with val loss: {val_loss:.6f}')\n","    \n","    # Load best model\n","    model.load_state_dict(best_model_state)\n","    return model\n"]},{"cell_type":"markdown","id":"be1602eb","metadata":{"papermill":{"duration":0.003174,"end_time":"2025-04-27T22:29:08.052698","exception":false,"start_time":"2025-04-27T22:29:08.049524","status":"completed"},"tags":[]},"source":["# Generate Test Predictions\n","The `generate_predictions` function generates 3D coordinate predictions for RNA sequences in the test set. It formats the predictions to match the competition's submission requirements."]},{"cell_type":"code","execution_count":8,"id":"2a02dacd","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:08.060261Z","iopub.status.busy":"2025-04-27T22:29:08.060067Z","iopub.status.idle":"2025-04-27T22:29:08.068249Z","shell.execute_reply":"2025-04-27T22:29:08.067636Z"},"papermill":{"duration":0.013174,"end_time":"2025-04-27T22:29:08.069295","exception":false,"start_time":"2025-04-27T22:29:08.056121","status":"completed"},"tags":[]},"outputs":[],"source":["# Generate test predictions\n","def generate_predictions(model, test_loader, test_sequences, sample_submission):\n","    model.eval()\n","    \n","    # Create test_clean dataframe (similar to original code)\n","    def parse_target(tmp_ID, tmp_sequence):\n","        seq_length = len(tmp_sequence)\n","        tmp_df = pd.DataFrame(columns=['ID', 'resname', 'resid'], index=range(seq_length))\n","        tmp_df['resname'] = list(tmp_sequence)\n","        tmp_df['ID'] = tmp_ID\n","        tmp_df['resid'] = range(1, seq_length + 1)\n","        return tmp_df\n","    \n","    test_id_seq = test_sequences[['target_id', 'sequence']]\n","    test_clean = pd.DataFrame(columns=['ID', 'resname', 'resid'])\n","    \n","    for index, row in test_id_seq.iterrows():\n","        tmp_df = parse_target(row['target_id'], row['sequence'])\n","        test_clean = pd.concat([test_clean, tmp_df], ignore_index=True)\n","    \n","    # Generate predictions\n","    predictions = {}\n","    \n","    with torch.no_grad():\n","        for batch in test_loader:\n","            target_ids = batch['target_id']\n","            sequences = batch['sequence']\n","            input_ids = batch['encoded_seq'].to(DEVICE)\n","            attention_mask = batch['attention_mask'].to(DEVICE)\n","            seq_lengths = batch['seq_length']\n","            \n","            # Get predictions\n","            pred_coords_list = model(input_ids, attention_mask)\n","            \n","            # Process each sequence\n","            for i, (target_id, seq_len) in enumerate(zip(target_ids, seq_lengths)):\n","                for j in range(seq_len):\n","                    key = f\"{target_id}_{j+1}\"\n","                    predictions[key] = {}\n","                    \n","                    # Save all 5 predictions\n","                    for k, pred_coords in enumerate(pred_coords_list):\n","                        predictions[key][f'x_{k+1}'] = pred_coords[i, j, 0].item()\n","                        predictions[key][f'y_{k+1}'] = pred_coords[i, j, 1].item()\n","                        predictions[key][f'z_{k+1}'] = pred_coords[i, j, 2].item()\n","    \n","    # Create submission dataframe\n","    for idx, row in test_clean.iterrows():\n","        key = f\"{row['ID']}_{row['resid']}\"\n","        if key in predictions:\n","            for col, value in predictions[key].items():\n","                test_clean.loc[idx, col] = value\n","    \n","    # Format submission to match sample submission\n","    submission = test_clean.copy()\n","    submission['ID'] = submission['ID'] + '_' + submission['resid'].astype(str)\n","    \n","    # Store original columns before adding sort_order\n","    original_columns = sample_submission.columns.tolist()\n","    \n","    # Add sort_order for sorting\n","    sample_submission['sort_order'] = range(len(sample_submission))\n","    \n","    # Use only the original columns for the merge\n","    submission = pd.merge(\n","        submission[original_columns], \n","        sample_submission[['ID', 'sort_order']], \n","        on='ID', \n","        how='left'\n","    ).sort_values('sort_order').drop(columns=['sort_order'])\n","    \n","    return submission\n"]},{"cell_type":"markdown","id":"036b4aef","metadata":{"papermill":{"duration":0.003231,"end_time":"2025-04-27T22:29:08.075921","exception":false,"start_time":"2025-04-27T22:29:08.07269","status":"completed"},"tags":[]},"source":["# Main Function\n","The main function initializes the dataset, data loaders, and model. It trains the model and generates predictions for submission."]},{"cell_type":"code","execution_count":9,"id":"d01817f4","metadata":{"execution":{"iopub.execute_input":"2025-04-27T22:29:08.084562Z","iopub.status.busy":"2025-04-27T22:29:08.084331Z","iopub.status.idle":"2025-04-27T23:19:00.537462Z","shell.execute_reply":"2025-04-27T23:19:00.536469Z"},"papermill":{"duration":2992.458614,"end_time":"2025-04-27T23:19:00.53915","exception":false,"start_time":"2025-04-27T22:29:08.080536","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Model initialized with 4528399 parameters\n","Epoch 1/20, Train Loss: 13818.658138, Val Loss: 15384615379289397437082193283252224.000000\n","New best model saved with val loss: 15384615379289397437082193283252224.000000\n","Epoch 2/20, Train Loss: 12674.812771, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 3/20, Train Loss: 12290.179637, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 4/20, Train Loss: 12625.946129, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 5/20, Train Loss: 12478.673197, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 6/20, Train Loss: 11637.013492, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 7/20, Train Loss: 13150.496911, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 8/20, Train Loss: 12012.893402, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 9/20, Train Loss: 11099.978099, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 10/20, Train Loss: 11824.362155, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 11/20, Train Loss: 11382.336082, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 12/20, Train Loss: 12481.643467, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 13/20, Train Loss: 12631.208154, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 14/20, Train Loss: 12007.738528, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 15/20, Train Loss: 12538.018234, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 16/20, Train Loss: 12406.073621, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 17/20, Train Loss: 12835.844363, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 18/20, Train Loss: 12835.543330, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 19/20, Train Loss: 12125.710402, Val Loss: 15384615379289397437082193283252224.000000\n","Epoch 20/20, Train Loss: 12577.841946, Val Loss: 15384615379289397437082193283252224.000000\n","Submission saved to submission.csv\n"]}],"source":["# Main function\n","print(f\"Using device: {DEVICE}\")\n","    \n","\n","    # Create datasets\n","train_dataset = RNADataset(train_sequences, train_labels)\n","val_dataset = RNADataset(validation_sequences, validation_labels)\n","test_dataset = RNADataset(test_sequences, is_test=True)\n","    \n","    # Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","    \n","    # Initialize model\n","model = RhoFoldPlus().to(DEVICE)\n","print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n","    \n","    # Train model\n","model = train_model(model, train_loader, val_loader)\n","    \n","    # Generate predictions\n","submission = generate_predictions(model, test_loader, test_sequences, sample_submission)\n","    \n","    # Save submission\n","submission.to_csv('submission.csv', index=False)\n","print(\"Submission saved to submission.csv\")\n","\n","\n"]},{"cell_type":"code","execution_count":10,"id":"5a22aec2","metadata":{"execution":{"iopub.execute_input":"2025-04-27T23:19:00.550026Z","iopub.status.busy":"2025-04-27T23:19:00.54981Z","iopub.status.idle":"2025-04-27T23:19:00.554439Z","shell.execute_reply":"2025-04-27T23:19:00.553672Z"},"papermill":{"duration":0.011769,"end_time":"2025-04-27T23:19:00.555997","exception":false,"start_time":"2025-04-27T23:19:00.544228","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/submission.csv\n","/kaggle/working/__notebook__.ipynb\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/working'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":11,"id":"5a21f814","metadata":{"execution":{"iopub.execute_input":"2025-04-27T23:19:00.572336Z","iopub.status.busy":"2025-04-27T23:19:00.572129Z","iopub.status.idle":"2025-04-27T23:19:00.608393Z","shell.execute_reply":"2025-04-27T23:19:00.607298Z"},"papermill":{"duration":0.045848,"end_time":"2025-04-27T23:19:00.609926","exception":false,"start_time":"2025-04-27T23:19:00.564078","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>resname</th>\n","      <th>resid</th>\n","      <th>x_1</th>\n","      <th>y_1</th>\n","      <th>z_1</th>\n","      <th>x_2</th>\n","      <th>y_2</th>\n","      <th>z_2</th>\n","      <th>x_3</th>\n","      <th>y_3</th>\n","      <th>z_3</th>\n","      <th>x_4</th>\n","      <th>y_4</th>\n","      <th>z_4</th>\n","      <th>x_5</th>\n","      <th>y_5</th>\n","      <th>z_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>R1107_1</td>\n","      <td>G</td>\n","      <td>1</td>\n","      <td>69.516190</td>\n","      <td>66.779793</td>\n","      <td>73.783150</td>\n","      <td>69.337814</td>\n","      <td>66.890190</td>\n","      <td>73.748993</td>\n","      <td>69.579681</td>\n","      <td>66.808212</td>\n","      <td>73.792976</td>\n","      <td>69.644089</td>\n","      <td>66.662796</td>\n","      <td>73.492615</td>\n","      <td>69.365211</td>\n","      <td>66.890549</td>\n","      <td>73.577278</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>R1107_2</td>\n","      <td>G</td>\n","      <td>2</td>\n","      <td>69.516182</td>\n","      <td>66.779785</td>\n","      <td>73.783142</td>\n","      <td>69.337814</td>\n","      <td>66.890175</td>\n","      <td>73.748985</td>\n","      <td>69.579681</td>\n","      <td>66.808205</td>\n","      <td>73.792969</td>\n","      <td>69.644081</td>\n","      <td>66.662796</td>\n","      <td>73.492607</td>\n","      <td>69.365204</td>\n","      <td>66.890533</td>\n","      <td>73.577271</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>R1107_3</td>\n","      <td>G</td>\n","      <td>3</td>\n","      <td>69.516190</td>\n","      <td>66.779793</td>\n","      <td>73.783150</td>\n","      <td>69.337814</td>\n","      <td>66.890175</td>\n","      <td>73.748985</td>\n","      <td>69.579681</td>\n","      <td>66.808205</td>\n","      <td>73.792961</td>\n","      <td>69.644081</td>\n","      <td>66.662788</td>\n","      <td>73.492607</td>\n","      <td>69.365189</td>\n","      <td>66.890533</td>\n","      <td>73.577271</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>R1107_4</td>\n","      <td>G</td>\n","      <td>4</td>\n","      <td>69.516182</td>\n","      <td>66.779793</td>\n","      <td>73.783150</td>\n","      <td>69.337822</td>\n","      <td>66.890175</td>\n","      <td>73.748993</td>\n","      <td>69.579681</td>\n","      <td>66.808205</td>\n","      <td>73.792969</td>\n","      <td>69.644089</td>\n","      <td>66.662804</td>\n","      <td>73.492615</td>\n","      <td>69.365204</td>\n","      <td>66.890533</td>\n","      <td>73.577271</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>R1107_5</td>\n","      <td>G</td>\n","      <td>5</td>\n","      <td>69.516190</td>\n","      <td>66.779785</td>\n","      <td>73.783142</td>\n","      <td>69.337822</td>\n","      <td>66.890175</td>\n","      <td>73.748985</td>\n","      <td>69.579689</td>\n","      <td>66.808212</td>\n","      <td>73.792976</td>\n","      <td>69.644089</td>\n","      <td>66.662796</td>\n","      <td>73.492607</td>\n","      <td>69.365204</td>\n","      <td>66.890541</td>\n","      <td>73.577278</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2510</th>\n","      <td>R1189_114</td>\n","      <td>U</td>\n","      <td>114</td>\n","      <td>69.516235</td>\n","      <td>66.779861</td>\n","      <td>73.783203</td>\n","      <td>69.337639</td>\n","      <td>66.889954</td>\n","      <td>73.748787</td>\n","      <td>69.580025</td>\n","      <td>66.808586</td>\n","      <td>73.793335</td>\n","      <td>69.644386</td>\n","      <td>66.663094</td>\n","      <td>73.492874</td>\n","      <td>69.364937</td>\n","      <td>66.890297</td>\n","      <td>73.577049</td>\n","    </tr>\n","    <tr>\n","      <th>2511</th>\n","      <td>R1189_115</td>\n","      <td>U</td>\n","      <td>115</td>\n","      <td>69.516251</td>\n","      <td>66.779861</td>\n","      <td>73.783218</td>\n","      <td>69.337646</td>\n","      <td>66.889946</td>\n","      <td>73.748764</td>\n","      <td>69.580025</td>\n","      <td>66.808586</td>\n","      <td>73.793358</td>\n","      <td>69.644394</td>\n","      <td>66.663109</td>\n","      <td>73.492874</td>\n","      <td>69.364929</td>\n","      <td>66.890274</td>\n","      <td>73.577026</td>\n","    </tr>\n","    <tr>\n","      <th>2512</th>\n","      <td>R1189_116</td>\n","      <td>U</td>\n","      <td>116</td>\n","      <td>69.516235</td>\n","      <td>66.779854</td>\n","      <td>73.783211</td>\n","      <td>69.337639</td>\n","      <td>66.889961</td>\n","      <td>73.748795</td>\n","      <td>69.580017</td>\n","      <td>66.808571</td>\n","      <td>73.793335</td>\n","      <td>69.644363</td>\n","      <td>66.663094</td>\n","      <td>73.492867</td>\n","      <td>69.364944</td>\n","      <td>66.890289</td>\n","      <td>73.577049</td>\n","    </tr>\n","    <tr>\n","      <th>2513</th>\n","      <td>R1189_117</td>\n","      <td>U</td>\n","      <td>117</td>\n","      <td>69.516251</td>\n","      <td>66.779861</td>\n","      <td>73.783218</td>\n","      <td>69.337639</td>\n","      <td>66.889954</td>\n","      <td>73.748772</td>\n","      <td>69.580032</td>\n","      <td>66.808594</td>\n","      <td>73.793358</td>\n","      <td>69.644386</td>\n","      <td>66.663109</td>\n","      <td>73.492882</td>\n","      <td>69.364929</td>\n","      <td>66.890266</td>\n","      <td>73.577026</td>\n","    </tr>\n","    <tr>\n","      <th>2514</th>\n","      <td>R1189_118</td>\n","      <td>U</td>\n","      <td>118</td>\n","      <td>69.516251</td>\n","      <td>66.779861</td>\n","      <td>73.783203</td>\n","      <td>69.337639</td>\n","      <td>66.889961</td>\n","      <td>73.748787</td>\n","      <td>69.580002</td>\n","      <td>66.808563</td>\n","      <td>73.793312</td>\n","      <td>69.644363</td>\n","      <td>66.663078</td>\n","      <td>73.492867</td>\n","      <td>69.364944</td>\n","      <td>66.890297</td>\n","      <td>73.577049</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2515 rows × 18 columns</p>\n","</div>"],"text/plain":["             ID resname  resid        x_1        y_1        z_1        x_2  \\\n","0       R1107_1       G      1  69.516190  66.779793  73.783150  69.337814   \n","1       R1107_2       G      2  69.516182  66.779785  73.783142  69.337814   \n","2       R1107_3       G      3  69.516190  66.779793  73.783150  69.337814   \n","3       R1107_4       G      4  69.516182  66.779793  73.783150  69.337822   \n","4       R1107_5       G      5  69.516190  66.779785  73.783142  69.337822   \n","...         ...     ...    ...        ...        ...        ...        ...   \n","2510  R1189_114       U    114  69.516235  66.779861  73.783203  69.337639   \n","2511  R1189_115       U    115  69.516251  66.779861  73.783218  69.337646   \n","2512  R1189_116       U    116  69.516235  66.779854  73.783211  69.337639   \n","2513  R1189_117       U    117  69.516251  66.779861  73.783218  69.337639   \n","2514  R1189_118       U    118  69.516251  66.779861  73.783203  69.337639   \n","\n","            y_2        z_2        x_3        y_3        z_3        x_4  \\\n","0     66.890190  73.748993  69.579681  66.808212  73.792976  69.644089   \n","1     66.890175  73.748985  69.579681  66.808205  73.792969  69.644081   \n","2     66.890175  73.748985  69.579681  66.808205  73.792961  69.644081   \n","3     66.890175  73.748993  69.579681  66.808205  73.792969  69.644089   \n","4     66.890175  73.748985  69.579689  66.808212  73.792976  69.644089   \n","...         ...        ...        ...        ...        ...        ...   \n","2510  66.889954  73.748787  69.580025  66.808586  73.793335  69.644386   \n","2511  66.889946  73.748764  69.580025  66.808586  73.793358  69.644394   \n","2512  66.889961  73.748795  69.580017  66.808571  73.793335  69.644363   \n","2513  66.889954  73.748772  69.580032  66.808594  73.793358  69.644386   \n","2514  66.889961  73.748787  69.580002  66.808563  73.793312  69.644363   \n","\n","            y_4        z_4        x_5        y_5        z_5  \n","0     66.662796  73.492615  69.365211  66.890549  73.577278  \n","1     66.662796  73.492607  69.365204  66.890533  73.577271  \n","2     66.662788  73.492607  69.365189  66.890533  73.577271  \n","3     66.662804  73.492615  69.365204  66.890533  73.577271  \n","4     66.662796  73.492607  69.365204  66.890541  73.577278  \n","...         ...        ...        ...        ...        ...  \n","2510  66.663094  73.492874  69.364937  66.890297  73.577049  \n","2511  66.663109  73.492874  69.364929  66.890274  73.577026  \n","2512  66.663094  73.492867  69.364944  66.890289  73.577049  \n","2513  66.663109  73.492882  69.364929  66.890266  73.577026  \n","2514  66.663078  73.492867  69.364944  66.890297  73.577049  \n","\n","[2515 rows x 18 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["subs = pd.read_csv(\"/kaggle/working/submission.csv\")\n","subs"]},{"cell_type":"code","execution_count":12,"id":"bcfd70e5","metadata":{"execution":{"iopub.execute_input":"2025-04-27T23:19:00.621296Z","iopub.status.busy":"2025-04-27T23:19:00.621034Z","iopub.status.idle":"2025-04-27T23:19:00.632637Z","shell.execute_reply":"2025-04-27T23:19:00.631709Z"},"papermill":{"duration":0.018494,"end_time":"2025-04-27T23:19:00.63401","exception":false,"start_time":"2025-04-27T23:19:00.615516","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["           ID resname resid        x_1        y_1        z_1        x_2  \\\n","1300  R1138_1       G     1  69.516235  66.779808  73.783203  69.337875   \n","1301  R1138_2       G     2  69.516220  66.779800  73.783188  69.337883   \n","1302  R1138_3       G     3  69.516235  66.779808  73.783203  69.337875   \n","1303  R1138_4       A     4  69.516228  66.779800  73.783203  69.337868   \n","1304  R1138_5       G     5  69.516228  66.779793  73.783195  69.337875   \n","\n","            y_2        z_2        x_3        y_3        z_3        x_4  \\\n","1300  66.890251  73.749046  69.579643  66.808159  73.792923  69.644073   \n","1301  66.890251  73.749046  69.579643  66.808151  73.792923  69.644066   \n","1302  66.890244  73.749046  69.579643  66.808151  73.792931  69.644066   \n","1303  66.890236  73.749039  69.579643  66.808159  73.792938  69.644066   \n","1304  66.890236  73.749039  69.579643  66.808151  73.792931  69.644073   \n","\n","            y_4        z_4        x_5        y_5        z_5  \n","1300  66.662773  73.492584  69.365211  66.890549  73.577309  \n","1301  66.662773  73.492577  69.365211  66.890541  73.577309  \n","1302  66.662766  73.492584  69.365219  66.890541  73.577301  \n","1303  66.662766  73.492584  69.365211  66.890533  73.577301  \n","1304  66.662766  73.492584  69.365204  66.890541  73.577286  \n"]}],"source":["# After generating submission but before saving\n","print(submission[submission['ID'].str.startswith('R1138_')].head())\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":11228175,"sourceId":87793,"sourceType":"competition"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":3002.019974,"end_time":"2025-04-27T23:19:03.053775","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-27T22:29:01.033801","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}